{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 204 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_datagen=ImageDataGenerator(\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rescale=1./255\n",
    "\n",
    ")\n",
    "training_set=image_datagen.flow_from_directory(\n",
    "    r'D:\\programming\\models\\dataset\\image_class\\Skin_Data\\train_set',\n",
    "    batch_size=32,\n",
    "    target_size=(64,64),\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "test_set=image_datagen.flow_from_directory(\n",
    "    r'D:\\programming\\models\\dataset\\image_class\\Skin_Data\\test_set',\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(activation='relu',filters=32,kernel_size=3,input_shape=[64,64,3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=1))\n",
    "cnn.add(tf.keras.layers.Conv2D(activation='relu',filters=32,kernel_size=3))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=1))\n",
    "cnn.add(tf.keras.layers.Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=100,activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))\n",
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=[['accuracy']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.3067 - accuracy: 0.8676 - val_loss: 0.8364 - val_accuracy: 0.5952\n",
      "Epoch 2/40\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.2638 - accuracy: 0.8824 - val_loss: 0.4836 - val_accuracy: 0.7976\n",
      "Epoch 3/40\n",
      "7/7 [==============================] - 1s 170ms/step - loss: 0.2750 - accuracy: 0.8922 - val_loss: 0.7157 - val_accuracy: 0.6310\n",
      "Epoch 4/40\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.2644 - accuracy: 0.8824 - val_loss: 0.7475 - val_accuracy: 0.6667\n",
      "Epoch 5/40\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.2270 - accuracy: 0.8971 - val_loss: 0.6506 - val_accuracy: 0.7024\n",
      "Epoch 6/40\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.2110 - accuracy: 0.9314 - val_loss: 0.7168 - val_accuracy: 0.6905\n",
      "Epoch 7/40\n",
      "7/7 [==============================] - 1s 163ms/step - loss: 0.2497 - accuracy: 0.8824 - val_loss: 0.9674 - val_accuracy: 0.6190\n",
      "Epoch 8/40\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.2283 - accuracy: 0.8873 - val_loss: 0.6276 - val_accuracy: 0.7262\n",
      "Epoch 9/40\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.2139 - accuracy: 0.9069 - val_loss: 0.6497 - val_accuracy: 0.7262\n",
      "Epoch 10/40\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.2082 - accuracy: 0.9069 - val_loss: 0.8336 - val_accuracy: 0.7024\n",
      "Epoch 11/40\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.2291 - accuracy: 0.9069 - val_loss: 0.4690 - val_accuracy: 0.7976\n",
      "Epoch 12/40\n",
      "7/7 [==============================] - 1s 163ms/step - loss: 0.2333 - accuracy: 0.8922 - val_loss: 0.8831 - val_accuracy: 0.6310\n",
      "Epoch 13/40\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.2113 - accuracy: 0.9167 - val_loss: 0.6883 - val_accuracy: 0.7143\n",
      "Epoch 14/40\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.1893 - accuracy: 0.9314 - val_loss: 0.7072 - val_accuracy: 0.7381\n",
      "Epoch 15/40\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.2114 - accuracy: 0.9265 - val_loss: 0.9034 - val_accuracy: 0.6905\n",
      "Epoch 16/40\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 0.1999 - accuracy: 0.9216 - val_loss: 0.5317 - val_accuracy: 0.7857\n",
      "Epoch 17/40\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.2104 - accuracy: 0.9020 - val_loss: 0.5083 - val_accuracy: 0.8214\n",
      "Epoch 18/40\n",
      "7/7 [==============================] - 1s 165ms/step - loss: 0.1886 - accuracy: 0.9216 - val_loss: 1.5122 - val_accuracy: 0.5952\n",
      "Epoch 19/40\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.2419 - accuracy: 0.9069 - val_loss: 0.7563 - val_accuracy: 0.7381\n",
      "Epoch 20/40\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.1814 - accuracy: 0.9216 - val_loss: 0.7042 - val_accuracy: 0.7500\n",
      "Epoch 21/40\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.1455 - accuracy: 0.9510 - val_loss: 1.0405 - val_accuracy: 0.6786\n",
      "Epoch 22/40\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.1594 - accuracy: 0.9265 - val_loss: 0.8565 - val_accuracy: 0.7024\n",
      "Epoch 23/40\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 0.1549 - accuracy: 0.9314 - val_loss: 0.6969 - val_accuracy: 0.7619\n",
      "Epoch 24/40\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 0.1389 - accuracy: 0.9265 - val_loss: 1.7091 - val_accuracy: 0.5833\n",
      "Epoch 25/40\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.1665 - accuracy: 0.9363 - val_loss: 0.5906 - val_accuracy: 0.7619\n",
      "Epoch 26/40\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.1391 - accuracy: 0.9314 - val_loss: 0.8601 - val_accuracy: 0.7262\n",
      "Epoch 27/40\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.1617 - accuracy: 0.9412 - val_loss: 1.0270 - val_accuracy: 0.6667\n",
      "Epoch 28/40\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.1284 - accuracy: 0.9559 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 29/40\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.1240 - accuracy: 0.9559 - val_loss: 0.8079 - val_accuracy: 0.7500\n",
      "Epoch 30/40\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.1475 - accuracy: 0.9363 - val_loss: 0.8498 - val_accuracy: 0.7619\n",
      "Epoch 31/40\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.1189 - accuracy: 0.9608 - val_loss: 0.9074 - val_accuracy: 0.7143\n",
      "Epoch 32/40\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.1013 - accuracy: 0.9608 - val_loss: 0.9908 - val_accuracy: 0.7143\n",
      "Epoch 33/40\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.0894 - accuracy: 0.9657 - val_loss: 0.8512 - val_accuracy: 0.7024\n",
      "Epoch 34/40\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.0939 - accuracy: 0.9706 - val_loss: 1.0531 - val_accuracy: 0.7381\n",
      "Epoch 35/40\n",
      "7/7 [==============================] - 1s 166ms/step - loss: 0.0862 - accuracy: 0.9706 - val_loss: 1.0097 - val_accuracy: 0.7262\n",
      "Epoch 36/40\n",
      "7/7 [==============================] - 1s 173ms/step - loss: 0.0925 - accuracy: 0.9608 - val_loss: 0.7351 - val_accuracy: 0.7857\n",
      "Epoch 37/40\n",
      "7/7 [==============================] - 1s 173ms/step - loss: 0.1015 - accuracy: 0.9608 - val_loss: 1.0846 - val_accuracy: 0.7381\n",
      "Epoch 38/40\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.0674 - accuracy: 0.9804 - val_loss: 1.4592 - val_accuracy: 0.6190\n",
      "Epoch 39/40\n",
      "7/7 [==============================] - 1s 205ms/step - loss: 0.0721 - accuracy: 0.9706 - val_loss: 1.0774 - val_accuracy: 0.7262\n",
      "Epoch 40/40\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.0745 - accuracy: 0.9706 - val_loss: 1.1196 - val_accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "ans=cnn.fit(training_set,validation_data=test_set,epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cancer': 0, 'non_cancer': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 361ms/step\n",
      "cancer\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import load_img,img_to_array\n",
    "test_image=load_img(r'D:\\programming\\models\\dataset\\image_class\\single_pred\\download.webp',target_size=(64,64))\n",
    "test_image=img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "result=cnn.predict(test_image)\n",
    "if result[0][0]==0:\n",
    "    print('cancer')\n",
    "else:\n",
    "    print(\"not cancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import load_img,img_to_array\n",
    "test_image=load_img(r'D:\\programming\\models\\dataset\\image_class\\single_pred\\not cancer.webp',target_size=(64,64))\n",
    "test_image=img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "result=cnn.predict(test_image)\n",
    "if result[0][0]==0:\n",
    "    print('cancer')\n",
    "else:\n",
    "    print(\"not cancer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
